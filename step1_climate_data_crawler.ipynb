{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/OpenHackFarm/CODiS_carwler/blob/master/climate_crawler.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# encoding: utf-8\n",
    "\n",
    "# 修改自 https://gist.github.com/wy36101299/e3b32c674d9e86ba581f\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "from time import sleep\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import os\n",
    "\n",
    "#PATH = '/home/yan/sync/project/Weather Station/CODiS/'\n",
    "\n",
    "PATH = './data/'\n",
    "\n",
    "#To create the directory if it doesn't exist\n",
    "if not os.path.exists(PATH):\n",
    "    os.mkdir(PATH)\n",
    "\n",
    "# 產生data List , data List為兩年份\n",
    "def date():\n",
    "    month31=[1,3,5,7,8,10,12]\n",
    "    month30=[4,6,9,11]\n",
    "    #year2=['2016','2017']\n",
    "    year2=['2016']\n",
    "    nday31=range(1,32)\n",
    "    nday30=range(1,31)\n",
    "    nday28=range(1,29)\n",
    "    day10=['01','02','03','04','05','06','07','08','09']\n",
    "    month12=day10+['10','11','12']\n",
    "    nday31 = map(str,nday31[9:])\n",
    "    nday30 = map(str,nday30[9:])\n",
    "    nday28 = map(str,nday28[9:])\n",
    "    day31 = day10 + list(nday31)\n",
    "    day30 = day10 + list(nday30)\n",
    "    day28 = day10 + list(nday28)\n",
    "    output=[]\n",
    "    s=\"\"\n",
    "    for year in year2:\n",
    "        for month,strmonth in zip(range(1,13),month12):\n",
    "            if month in month31:\n",
    "                for day in day31:\n",
    "                    s = year+'-'+strmonth+'-'+day\n",
    "                    output.append(s)\n",
    "            elif month in month30:\n",
    "                for day in day30:\n",
    "                    s = year+'-'+strmonth+'-'+day\n",
    "                    output.append(s)\n",
    "            else:\n",
    "                for day in day28:\n",
    "                    s = year+'-02-'+day\n",
    "                    output.append(s)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 爬取主函式\n",
    "def crawler(url,name):\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.text)\n",
    "\n",
    "    form =[]\n",
    "    # title\n",
    "    second_tr = soup.find(class_=\"second_tr\")\n",
    "    titles = soup.find_all(\"th\")\n",
    "    titles = titles[9:]\n",
    "    strtitle=[]\n",
    "    for title in titles:\n",
    "        title = title.contents\n",
    "        title=title[0]+title[2]+title[4]\n",
    "        strtitle.append(title)\n",
    "\n",
    "    # parameter\n",
    "    soup = soup.tbody\n",
    "    tmps = soup.find_all(\"tr\")\n",
    "    tmps = tmps[2:]\n",
    "    for tmp in tmps:\n",
    "        tmp = tmp.find_all(\"td\")\n",
    "        parameter =[]\n",
    "        for strtmp in tmp:\n",
    "            strtmp = strtmp.string\n",
    "            parameter .append(strtmp)\n",
    "        form.append(parameter)\n",
    "\n",
    "    form = pd.DataFrame(form, columns=strtitle)\n",
    "    form.to_csv(PATH + name + \".txt\", encoding =\"utf-8\")\n",
    "    sleep(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-58f1b7ba25cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdownload\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mhostUrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"http://e-service.cwb.gov.tw/HistoryDataQuery/DayDataController.do?\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mfixedParameter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"command=viewMain\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mcsvFile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'TaiwanWeatherSatation.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    download = date()\n",
    "    hostUrl = \"http://e-service.cwb.gov.tw/HistoryDataQuery/DayDataController.do?\"\n",
    "    fixedParameter = \"command=viewMain\"\n",
    "    csvFile = open('TaiwanWeatherSatation.csv')\n",
    "\n",
    "    for date in download:\n",
    "        # 此為宜蘭站的觀測資料\n",
    "        #url=\"http://e-service.cwb.gov.tw/HistoryDataQuery/DayDataController.do?command=viewMain&station=467080&stname=%25E5%25AE%259C%25E8%2598%25AD&datepicker=\"+date\n",
    "    \n",
    "        print(date)\n",
    "        try:\n",
    "            crawler(url,date)\n",
    "            print(url)\n",
    "\n",
    "        except:\n",
    "            # 若是爬取失敗把該日期寫入error.txt\n",
    "            with open (PATH + \"error.txt\",'a') as f:\n",
    "                f.write(date+'\\n')\n",
    "            csvFile.close()\n",
    "\n",
    "    csvFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "must be str, not function",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d88a58942d24>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0murl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"http://e-service.cwb.gov.tw/HistoryDataQuery/DayDataController.do?command=viewMain&station=467080&stname=%25E5%25AE%259C%25E8%2598%25AD&datepicker=\"\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"T\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mcrawler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mresp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: must be str, not function"
     ]
    }
   ],
   "source": [
    "url=\"http://e-service.cwb.gov.tw/HistoryDataQuery/DayDataController.do?command=viewMain&station=467080&stname=%25E5%25AE%259C%25E8%2598%25AD&datepicker=\"+date\n",
    "name=\"A\"\n",
    "def crawler(url,name):\n",
    "    resp = requests.get(url)\n",
    "    soup = BeautifulSoup(resp.text)\n",
    "\n",
    "    form =[]\n",
    "    # title\n",
    "    second_tr = soup.find(class_=\"second_tr\")\n",
    "    titles = soup.find_all(\"th\")\n",
    "    titles = titles[9:]\n",
    "    strtitle=[]\n",
    "    for title in titles:\n",
    "        title = title.contents\n",
    "        title=title[0]+title[2]+title[4]\n",
    "        strtitle.append(title)\n",
    "\n",
    "    # parameter\n",
    "    soup = soup.tbody\n",
    "    tmps = soup.find_all(\"tr\")\n",
    "    tmps = tmps[2:]\n",
    "    for tmp in tmps:\n",
    "        tmp = tmp.find_all(\"td\")\n",
    "        parameter =[]\n",
    "        for strtmp in tmp:\n",
    "            strtmp = strtmp.string\n",
    "            parameter .append(strtmp)\n",
    "        form.append(parameter)\n",
    "\n",
    "    form = pd.DataFrame(form, columns=strtitle)\n",
    "    form.to_csv(PATH + name + \".txt\", encoding =\"utf-8\")\n",
    "    sleep(0.5)\n",
    "crawler(url,name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
